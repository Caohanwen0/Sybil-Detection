3 无监督学习
本文基于SybilBlind算法进行虚假用户的无监督学习[1]。
3.1 无监督学习的必要性
（1）针对一个大的数据集，手动标注虚假用户非常耗费时间。
（2）有监督学习需要基于大量的特征识别虚假用户，而这些特征是随时间变化的且可人工反检测，因而有监督学习模型不具有良好的时效性。
3.2 本文无监督学习基本假设
网络属于同质网络（homophily network），即该网络中任一条连边的两个端点大概率是同类用户（同为正常用户或同为虚假用户）。
3.3 SybilBlind
首先从整个网络中选取一小部分用户节点（如整个网络总共有1000个节点，可以选出20个节点），随机分为相等的两组B和S，对其中B全部标为正常用户，另一组S全部标为虚假用户。设n_bb表示B中的正常用户的个数，n_bs表示B中的虚假用户个数，n_sb表示S中的正常用户个数，n_ss表示S中的虚假用户个数。然后我们定义三种极化如下
正极化：n_bb>n_sb且n_bs<n_ss
负极化：n_bb<n_sb且n_bs>n_ss
非极化：n_bb=n_sb且n_bs=n_ss
不难发现，在正极化情况下，我们给定的大多数随机初始标签与用户真实标签相同；在负极化情况下，我们给定的大多数随机初始标签与用户真实标签相反；在非极化情况下，给定的随机初始标签一半正确，一半错误。
注意，在给定随机初始标签之后，我们使用基于网络结构和随机游走的SybilSCAR[2]算法对其他用户节点做出分类判断，在同质网络的假设下，若发生负极化，则意味着经过足够多的随机游走迭代次数之后，原来网络中的绝大多数正常用户节点会被判断为虚假用户节点，这是我们所不希望发生的；反之，我们希望的是正极化的情况。下面，我们根据预测标签网络的同质性和熵两个指标对以上所提及的三种极化情况做出识别，以便我们选择正极化的结果。
定义同质性h和熵e如下
h=(#homogeneous)/(#edges in total)
e={█(0,&s>0.5@-slog(s)-(1-s)log⁡(1-s),&otherwise)┤
其中，#homogeneous表示网络中两个端点的预测类别相同的边的个数，#edges in total为网络中总的边数，s表示网络中被预测为虚假用户的用户所占的比例。由于现实中的社交网络往往是正常用户多于虚假用户（如Twitter网络中虚假用户大约只占10%），故当负极化发生时，由于多数正常用户会被预测为虚假用户，故最终预测为虚假用户的节点会超过50%，也即s>0.5。这样我们就可以通过e=0识别出这种负极化的情况；而当非极化发生时，节点标签的预测更接近于随机预测，因而同质性会很差，所以我们可通过同质性h特别小识别出非极化的情况；而当同质性h和熵e都比较大时，就是我们所希望的正极化情况。
事实上，我们会重复做大量随机初始标签的实验，然后首先从中选出同质性前k大的实验，再从这k个样本中选择e最大的那一次实验的预测结果作为我们无监督学习的预测结果。这样得到的预测结果通常对应的是正极化中能够检测出最多虚假用户的结果（熵e≥0，且随s在(0,1/2)上单调递增，在(1/2,1)上单调递减）。
我们再来分析一下SybilBlind算法的时间复杂度。在每次实验的每轮迭代中，需要从一个节点出发遍历其所有邻居节点，然后再遍历其邻居节点的邻居节点……平均时间复杂度为O(|E|)。因而若一共进行N次重复实验，每次实验随机游走迭代T步，总共时间复杂度就是O(KT|E|)。
3.4 实验验证
我们选取soc-Epinions数据集的前五万个用户节点极其之间的连边（约46万条连边），全部标为正常用户；然后，通过优先链接（PA）模型生成一个具有8790个节点及其连边的网络（约35000条连边），全部标为虚假用户；最后添加“attack edges”，attack edges即表示正常用户和虚假用户之间的连边（由于同质网络的假设，要注意不能生成过多attack edges）。我们分别添加100、500、1000、3000、5000、8000、10000、15000、20000、30000、50000、100000条attack edges，将预测结果得到的accuracy、precision以及recall指标绘制成三条随attack edges数量变化的曲线如下：
 
不难发现，当attack edges个数小于10000时，该网络保持有比较好的预测性能，可认为该网络属于同质网络；而当attack edges个数大于10000时，该网络对虚假用户的预测性能变得很差，可认为此时其不再满足同质性假设，从而不再适用于SybilBlind算法。由此，我们也可以了解到当网络中异质边占所有边的比例小于2%时，可认为该网络为同质网络；否则应认为该网络不是同质网络。
4 总结
在数据集有标签的情况下，构建关于网络结构和节点信息两方面的特征，随机森林分类器效果最好、最可信。
在数据集无标签的情况下，采用SybilBlind算法，重复多次实验，并用同质性和熵两个指标将结果进行聚合，在网络满足同质性假设的情况下可得到高可信度的分类结果。
